{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916d9412-188f-4136-9a45-26ce9c33d931",
   "metadata": {},
   "source": [
    "Notwenige Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcadf346-04f4-479e-8b3b-140ff8a858e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")  # Falls noch nicht gesetzt\n",
    "\n",
    "from audio_data import AudioDataSet\n",
    "from feature_set import FeatureSet\n",
    "from classifier import DroneClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5533e2-d394-4f03-8f04-537baea744bd",
   "metadata": {},
   "source": [
    "Konfigurationsfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35dc1f58-5ba0-4106-a295-f9ad12f87d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"sample_rate\": 16000,\n",
    "    \"audio_length\": 1, # in Sekunden\n",
    "    \"train_path\": \"d:/Dropbox/03 H2 Think/AuDroK mFund/Auswertungen/Datensätze/Drone vs. No Drone/TRAINING/\",\n",
    "    \"val_path\":   \"d:/Dropbox/03 H2 Think/AuDroK mFund/Auswertungen/Datensätze/Drone vs. No Drone/VALIDATION/\",\n",
    "    \"model_file\": \"models/classifier_001.keras\",\n",
    "    \"feature_files\": {\n",
    "        \"train_features\": \"models/train_features.pkl\",\n",
    "        \"val_features\": \"models/val_features.pkl\",\n",
    "        \"train_labels\": \"models/train_labels.pkl\",\n",
    "        \"val_labels\": \"models/val_labels.pkl\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bb7607-a44c-4390-8112-77a68a4ac6ae",
   "metadata": {},
   "source": [
    "Rohdaten fürs Training laden und inspizieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a82e8d5-01a9-4fe2-b1f2-6947f4cb1a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio files (3267 files to process):\n",
      "[#######################################.] 99.45%\n"
     ]
    }
   ],
   "source": [
    "raw_data_train = AudioDataSet.from_path(\n",
    "    path=config[\"train_path\"],\n",
    "    sample_rate=config[\"sample_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3fbc1c-f93e-45c6-8157-cb6832c002f1",
   "metadata": {},
   "source": [
    "Apply Pre-Emphasis auf die Trainingsrohdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa655e83-5a06-494d-9a65-e7537c15ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio in raw_data_train.audio:\n",
    "    audio.apply_pre_emphasis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252ab7a-0293-4fde-a1e1-08d4c45a5dfa",
   "metadata": {},
   "source": [
    "Chunken der Trainingsrohdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345182d7-a456-420e-a7c6-65c16e626bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39171 Chunks\n"
     ]
    }
   ],
   "source": [
    "chunk_length = config[\"sample_rate\"] * config[\"audio_length\"]\n",
    "chunked_data_train = raw_data_train.chunk_all(chunk_length)\n",
    "print(f\"{len(chunked_data_train.audio)} Chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34e838-82f0-4c8b-9364-e9813e28d567",
   "metadata": {},
   "source": [
    "Zwischenspeichern der Trainingsdaten zur Vereinfachung des Debuggings (kann später wieder entfernt werden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a5c11a-e234-495d-8d22-6b4cc22eb31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern\n",
    "import pickle\n",
    "\n",
    "with open(\"chunked_data_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunked_data_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d74a74-0534-487c-83ab-bdcb52528fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden\n",
    "import pickle\n",
    "\n",
    "with open(\"chunked_data_train.pkl\", \"rb\") as f:\n",
    "    chunked_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3fdb1-4afd-4e61-869f-50991ff294c0",
   "metadata": {},
   "source": [
    "Augmentieren der Chunks durch das Hinzufügen von Bodenreflexionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "955b7c04-f8c4-4f02-a503-33dd969a2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentations import apply_ground_reflection_to_dataset\n",
    "\n",
    "ranges = {\n",
    "    \"src_x\": (-10, 10),\n",
    "    \"src_y\": (-10, 10),\n",
    "    \"src_z\": (1, 5),\n",
    "    \"mic_z\": (1, 2),\n",
    "    \"attenuation\": (0.05, 0.95)\n",
    "}\n",
    "\n",
    "augmented_train_data = apply_ground_reflection_to_dataset(\n",
    "    dataset=chunked_data_train,\n",
    "    sample_rate=config[\"sample_rate\"],\n",
    "    ranges=ranges\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6725dbce-6712-4f26-bcdb-cb8a9158499b",
   "metadata": {},
   "source": [
    "Rohdaten für die Validierung laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e3ad580-aed3-46ae-a8b1-993216db5d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio files (277 files to process):\n",
      "[####################################....] 92.42%\n"
     ]
    }
   ],
   "source": [
    "raw_data_val = AudioDataSet.from_path(\n",
    "    path=config[\"val_path\"],\n",
    "    sample_rate=config[\"sample_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c798f5-b0fb-4f3a-b133-6a71bf195d1c",
   "metadata": {},
   "source": [
    "Apply Pre-Emphasis auf die Validierungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c0e13a-aeb7-4718-abf4-cc885220ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio in raw_data_val.audio:\n",
    "    audio.apply_pre_emphasis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708bb0e-8838-4f6f-b4af-fac3dc930cfc",
   "metadata": {},
   "source": [
    "Chunken der Validierungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d0d85c0-e896-40ac-8fb5-f350fe04334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34211 Chunks\n"
     ]
    }
   ],
   "source": [
    "chunk_length = config[\"sample_rate\"] * config[\"audio_length\"]\n",
    "chunked_data_val = raw_data_val.chunk_all(chunk_length)\n",
    "print(f\"{len(chunked_data_val.audio)} Chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375c9d5-7c1b-448f-bee5-cdbbfcff5005",
   "metadata": {},
   "source": [
    "Zwischenspeichern der Validierungsdaten zur Vereinfachung des Debuggings (kann später wieder entfernt werden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96258841-a73a-4d69-8616-bb72d169b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern\n",
    "import pickle\n",
    "\n",
    "with open(\"chunked_data_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunked_data_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9408bb-dde0-47ea-a5c1-10333c5d7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden\n",
    "import pickle\n",
    "\n",
    "with open(\"chunked_data_val.pkl\", \"rb\") as f:\n",
    "    chunked_data_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33082085-68b2-477c-ab48-bcfe39166a98",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00c5001b-42d3-4f91-9e51-44fcfdb75025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing features (39171 files to process):\n",
      "[########################################] 100.00%\n",
      "Processing features (34211 files to process):\n",
      "[########################################] 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Feature-Extraktion\n",
    "train_features = FeatureSet(augmented_train_data, sample_rate=config[\"sample_rate\"])\n",
    "X_train, y_train = train_features.extract()\n",
    "\n",
    "val_features = FeatureSet(chunked_data_val, sample_rate=config[\"sample_rate\"])\n",
    "X_val, y_val = val_features.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ed313-2112-4489-9a8a-783971bf0289",
   "metadata": {},
   "source": [
    "Modelltraining & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e930fa3-4988-4719-9152-0f3990231696",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DroneClassifier(model_path=\"models/classifier_003.h5\", trainable_layers=0)\n",
    "model.train(X_train, y_train, X_val, y_val)\n",
    "accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "print(f\"Validierungsgenauigkeit: {accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
