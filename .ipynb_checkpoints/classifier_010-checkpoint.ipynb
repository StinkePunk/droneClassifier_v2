{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916d9412-188f-4136-9a45-26ce9c33d931",
   "metadata": {},
   "source": [
    "Notwenige Importe und Konfigurationsfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcadf346-04f4-479e-8b3b-140ff8a858e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1266743544.py, line 15)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"model_file\": \"models/classifier_001.keras\",\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import collections\n",
    "sys.path.append(\"src\")  # Falls noch nicht gesetzt\n",
    "\n",
    "from audio_data import AudioDataSet\n",
    "from feature_set import FeatureSet\n",
    "from drone_classifier import DroneClassifier\n",
    "\n",
    "config = {\n",
    "    \"sample_rate\": 16000,\n",
    "    \"audio_length\": 1, # in Sekunden\n",
    "    \"train_path\": \"d:/Dropbox/03 H2 Think/AuDroK mFund/Auswertungen/Datensätze/Drone vs. No Drone/TRAINING/\",\n",
    "    \"val_path\":   \"d:/Dropbox/03 H2 Think/AuDroK mFund/Auswertungen/Datensätze/Drone vs. No Drone/VALIDATION/\",\n",
    "    \"rir_dir\":    \"d:/Dropbox/03 H2 Think/AuDroK mFund/Auswertungen/RIRs/\",\n",
    "    \"model_file\": \"models/classifier_001.keras\",\n",
    "    \"feature_files\": {\n",
    "        \"train_features\": \"models/train_features.pkl\",\n",
    "        \"val_features\": \"models/val_features.pkl\",\n",
    "        \"train_labels\": \"models/train_labels.pkl\",\n",
    "        \"val_labels\": \"models/val_labels.pkl\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bb7607-a44c-4390-8112-77a68a4ac6ae",
   "metadata": {},
   "source": [
    "Rohdaten fürs Training laden\n",
    "\n",
    "Pre-Emphasis anwenden\n",
    "\n",
    "chunken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2489b8-6491-46df-9506-4e45fa202ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des Audiodatensatzes für die Trainingsdaten\n",
    "raw_data_train = AudioDataSet.from_path(\n",
    "    path=config[\"train_path\"],\n",
    "    sample_rate=config[\"sample_rate\"]\n",
    ")\n",
    "\n",
    "# Apply Pre-Emphasis auf die Trainingsrohdaten\n",
    "for audio in raw_data_train.audio:\n",
    "    audio.apply_pre_emphasis()\n",
    "\n",
    "# Chunken der Trainingsrohdaten\n",
    "chunk_length = config[\"sample_rate\"] * config[\"audio_length\"]\n",
    "chunked_data_train = raw_data_train.chunk_all(chunk_length)\n",
    "print(f\"{len(chunked_data_train.audio)} Chunks\")\n",
    "\n",
    "from collections import Counter\n",
    "import random, copy\n",
    "from audio_data import AudioDataSet\n",
    "\n",
    "# Klassen zählen\n",
    "print(\"Train class dist:\", Counter([a.label for a in chunked_data_train.audio]))\n",
    "\n",
    "# Split nach Label\n",
    "dr = [a for a in chunked_data_train.audio if a.label == \"drone\"]\n",
    "nd = [a for a in chunked_data_train.audio if a.label == \"no drone\"]\n",
    "\n",
    "# Anzahl angleichen (Oversampling von no drone)\n",
    "needed = max(0, len(dr) - len(nd))\n",
    "nd_extra = [copy.deepcopy(random.choice(nd)) for _ in range(needed)]\n",
    "\n",
    "# Augmentieren, damit es nicht 1:1 Duplikate sind\n",
    "from augmentations import apply_ground_reflection_to_dataset\n",
    "ranges = {\"src_x\": (-10, 10), \"src_y\": (-10, 10), \"src_z\": (1, 5),\n",
    "          \"mic_z\": (1, 2), \"attenuation\": (0.05, 0.95)}\n",
    "nd_extra_ds = apply_ground_reflection_to_dataset(AudioDataSet(nd_extra),\n",
    "                                                 sample_rate=config[\"sample_rate\"],\n",
    "                                                 ranges=ranges)\n",
    "\n",
    "# Neues balanciertes Trainingsset\n",
    "balanced_train_data = AudioDataSet(dr + nd + nd_extra_ds.audio)\n",
    "\n",
    "# Zwischenspeichern der Trainingsdaten zur Vereinfachung des Debuggings\n",
    "import pickle\n",
    "\n",
    "with open(\"chunked_data_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunked_data_train, f)\n",
    "\n",
    "import collections\n",
    "print(collections.Counter([a.label for a in chunked_data_train.audio]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c31da-3efa-44fe-ae44-608a458c6c2b",
   "metadata": {},
   "source": [
    "Laden der zwischengespeicherten Gechunkten und vorverarbeiteten Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d74a74-0534-487c-83ab-bdcb52528fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Laden\n",
    "#import pickle\n",
    "#\n",
    "#with open(\"chunked_data_train.pkl\", \"rb\") as f:\n",
    "#    chunked_data_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6725dbce-6712-4f26-bcdb-cb8a9158499b",
   "metadata": {},
   "source": [
    "Rohdaten für die Validierung laden\n",
    "\n",
    "Pre-Emphasis anwenden\n",
    "\n",
    "chunken\n",
    "\n",
    "Zwischenspeichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ad580-aed3-46ae-a8b1-993216db5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_val = AudioDataSet.from_path(\n",
    "    path=config[\"val_path\"],\n",
    "    sample_rate=config[\"sample_rate\"]\n",
    ")\n",
    "\n",
    "# Pre-Emphasis\n",
    "for audio in raw_data_val.audio:\n",
    "    audio.apply_pre_emphasis()\n",
    "\n",
    "# Chunken\n",
    "chunk_length = config[\"sample_rate\"] * config[\"audio_length\"]\n",
    "chunked_data_val = raw_data_val.chunk_all(chunk_length)\n",
    "print(f\"{len(chunked_data_val.audio)} Chunks\")\n",
    "\n",
    "# Zwischenspeichern der vorverarbeiteten Validierungsdaten\n",
    "import pickle\n",
    "\n",
    "with open(\"chunked_data_val.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunked_data_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76478ad1-19c8-4b47-b674-1cc33e7f4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(\"Train:\", Counter([a.label for a in chunked_data_train.audio]))\n",
    "print(\"Val  :\", Counter([a.label for a in chunked_data_val.audio]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375c9d5-7c1b-448f-bee5-cdbbfcff5005",
   "metadata": {},
   "source": [
    "Laden der zwischengespeicherten vorverarbeiteten Validierungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9408bb-dde0-47ea-a5c1-10333c5d7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Laden\n",
    "#import pickle\n",
    "#\n",
    "#with open(\"chunked_data_val.pkl\", \"rb\") as f:\n",
    "#    chunked_data_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd688e-dbe2-480a-8c5d-5ff2caf34e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cb660-efb8-4c5d-8331-f07178a6820f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e8f47a-e196-4898-856e-6c672073e820",
   "metadata": {},
   "source": [
    "Augmentieren der TRainingsdaten durch das Hinzufügen von Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955b7c04-f8c4-4f02-a503-33dd969a2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Noise-Augmentierung im Dataset-Stil (ohne X_/y_-Vorgriffe) ---\n",
    "\n",
    "from augmentations import apply_noise_augmentation\n",
    "from audio_data import AudioDataSet\n",
    "\n",
    "# 1) Noise-Dataset aus echten No-Drone-Validierungs-Chunks bauen\n",
    "noise_from_val = [a for a in chunked_data_val.audio if a.label.lower() in (\"no drone\", \"no_drone\", \"no-drone\")]\n",
    "noise_ds = AudioDataSet(noise_from_val)\n",
    "\n",
    "# 2) Drohnen im Trainingsset separieren (balanced_train_data existiert bei dir bereits)\n",
    "drone_train = [a for a in balanced_train_data.audio if a.label.lower() == \"drone\"]\n",
    "no_drone_train = [a for a in balanced_train_data.audio if a.label.lower() != \"drone\"]\n",
    "\n",
    "drone_train_ds = AudioDataSet(drone_train)\n",
    "no_drone_train_ds = AudioDataSet(no_drone_train)\n",
    "\n",
    "# 3) Drohnen mit Val-Noise mischen (SNR-Logik steckt in apply_noise_augmentation)\n",
    "#    max_snr_db belassen oder moderat setzen. Höher = weniger Noise, niedriger/negativ = mehr Noise.\n",
    "aug_drone_ds = apply_noise_augmentation(\n",
    "    drone_dataset=drone_train_ds,\n",
    "    noise_dataset=no_drone_train_ds if len(no_drone_train) > 0 else noise_ds,  # Fallback\n",
    "    sample_rate=config[\"sample_rate\"],\n",
    "    # max_snr_db=-6  # optional anpassen, falls du härtere Bedingungen willst\n",
    ")\n",
    "\n",
    "# 4) Neues Trainings-Dataset zusammensetzen: (augmentierte Drohnen) + (No-Drone unverändert)\n",
    "augmented_train_data = AudioDataSet(aug_drone_ds.audio + no_drone_train_ds.audio)\n",
    "\n",
    "# 5) Optional: dezentes Echo oben drauf (deine bestehende Funktion arbeitet ebenfalls auf AudioDataSet)\n",
    "from augmentations import apply_ground_reflection_to_dataset\n",
    "ranges = {\"src_x\": (-10, 10), \"src_y\": (-10, 10), \"src_z\": (1, 5),\n",
    "          \"mic_z\": (1, 2), \"attenuation\": (0.05, 0.95)}\n",
    "augmented_train_data = apply_ground_reflection_to_dataset(\n",
    "    augmented_train_data, sample_rate=config[\"sample_rate\"], ranges=ranges\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33082085-68b2-477c-ab48-bcfe39166a98",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c5001b-42d3-4f91-9e51-44fcfdb75025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Extraktion (liefert X_*, y_*)\n",
    "train_features = FeatureSet(augmented_train_data, sample_rate=config[\"sample_rate\"])\n",
    "X_train, y_train = train_features.extract()\n",
    "\n",
    "val_features = FeatureSet(chunked_data_val, sample_rate=config[\"sample_rate\"])\n",
    "X_val, y_val = val_features.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376b312-e5dc-4158-a35f-9a0cc3d01f84",
   "metadata": {},
   "source": [
    "Zwischenspeichern der Features zur Vereinfachung des Debuggings (funktioniert derzeit nicht korrekt, beim Laden ändert sich das Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab59af-7161-4220-9f71-b25c7ce25b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speichern\n",
    "#import pickle\n",
    "#\n",
    "#with open(\"features.pkl\", \"wb\") as f:\n",
    "#    pickle.dump({\n",
    "#        \"X_train\": X_train,\n",
    "#        \"y_train\": y_train,\n",
    "#        \"X_val\": X_val,\n",
    "#        \"y_val\": y_val\n",
    "#    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a709b3c-ba73-40cc-860f-386aa4b738eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Laden\n",
    "#import pickle\n",
    "#\n",
    "#with open(\"features.pkl\", \"rb\") as f:\n",
    "#    data = pickle.load(f)\n",
    "\n",
    "#X_train = data[\"X_train\"]\n",
    "#y_train = data[\"y_train\"]\n",
    "#X_val = data[\"X_val\"]\n",
    "#y_val = data[\"y_val\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ed313-2112-4489-9a8a-783971bf0289",
   "metadata": {},
   "source": [
    "Modelltraining & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e930fa3-4988-4719-9152-0f3990231696",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DroneClassifier(model_path=\"models/classifier_010.keras\", trainable_layers=5)\n",
    "model.train(X_train, y_train, X_val, y_val)\n",
    "accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "print(f\"Validierungsgenauigkeit: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd684537-2de1-4652-9b9b-4844d1916a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
